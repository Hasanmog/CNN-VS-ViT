{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from model import Detector\n",
    "from PIL import Image\n",
    "from utils import file_format_counter\n",
    "from dataloader import SARDet\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/hasanmog/CNN-VS-ViT/Datasets/SARDet\"\n",
    "train = os.listdir(os.path.join(data_dir + '/train'))\n",
    "val = os.listdir(os.path.join(data_dir + '/val'))\n",
    "len(train) , len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(50)\n",
    "random.shuffle(train)\n",
    "test = train[70000:]\n",
    "train = train[:70000]\n",
    "len(train) , len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6000\n",
    "img = Image.open(os.path.join(data_dir+'/train/'+train[index]))\n",
    "print(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png , jpg ,bmp = file_format_counter(train)         \n",
    "print(f\"train_set: png={png} , jpg={jpg} , bmp={bmp}\")\n",
    "png , jpg ,bmp = file_format_counter(val)         \n",
    "print(f\"val_set: png={png} , jpg={jpg} , bmp={bmp}\")\n",
    "png , jpg ,bmp = file_format_counter(test)         \n",
    "print(f\"test_set: png={png} , jpg={jpg} , bmp={bmp}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = os.path.join(data_dir+'/train.json')\n",
    "val_json = os.path.join(data_dir+'/val.json')\n",
    "\n",
    "with open(train_json , 'r') as file:\n",
    "    train_anno = json.load(file)\n",
    "    \n",
    "train_anno.keys() , train_anno['images'][0] , train_anno['annotations'][0] , train_anno['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SARDet(data_dir= data_dir , imgs = train , mode = 'train')\n",
    "val_set = SARDet(data_dir= data_dir , imgs = val , mode = 'val')\n",
    "test_set = SARDet(data_dir= data_dir , imgs = test , mode = 'test')\n",
    "len(train_set) , len(val_set) , len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = val_set[4]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sample['image_tensor'].numpy()\n",
    "image = np.transpose(image , (1 , 2 , 0))\n",
    "print(\"image size : \" , image.shape)\n",
    "\n",
    "fig , ax = plt.subplots(1)\n",
    "ax.imshow(image , cmap='viridis')\n",
    "\n",
    "for i in range(len(sample['bboxes'])):\n",
    "    box = sample['bboxes'][i]\n",
    "    rect = patches.Rectangle((box[0], box[1]), box[2], box[3], linewidth=3, edgecolor='r', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detector().to(device)\n",
    "summary(model , input_size=(3,256 , 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1, 3, (800, 800, 3))  # Generate a random 800x800 image with 3 channels (RGB)\n",
    "input_tensor = torch.from_numpy(input_array).float()  # Convert to float tensor\n",
    "\n",
    "# Permute dimensions to match [N, C, H, W] format expected by PyTorch convolutional layers\n",
    "input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Assuming the model expects floating point data normalized to [0, 1]\n",
    "input_tensor /= 3  # Simple scaling by max value of np.random.randint range to bring values between 0 and 1\n",
    "input_tensor = input_tensor.to(device)\n",
    "# Pass the input tensor through the model\n",
    "outputs = model(input_tensor)  # Ensure model is in evaluation mode if not training: model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN-VS-ViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
