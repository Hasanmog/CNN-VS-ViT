{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from model import Detector\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import file_format_counter\n",
    "from dataloader import SARDet\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/hasanmog/CNN-VS-ViT/Datasets/SARDet\"\n",
    "train = os.listdir(os.path.join(data_dir + '/train'))\n",
    "val = os.listdir(os.path.join(data_dir + '/val'))\n",
    "len(train) , len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(50)\n",
    "random.shuffle(train)\n",
    "test = train[70000:]\n",
    "train = train[:70000]\n",
    "len(train) , len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6000\n",
    "img = Image.open(os.path.join(data_dir+'/train/'+train[index]))\n",
    "print(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png , jpg ,bmp = file_format_counter(train)         \n",
    "print(f\"train_set: png={png} , jpg={jpg} , bmp={bmp}\")\n",
    "png , jpg ,bmp = file_format_counter(val)         \n",
    "print(f\"val_set: png={png} , jpg={jpg} , bmp={bmp}\")\n",
    "png , jpg ,bmp = file_format_counter(test)         \n",
    "print(f\"test_set: png={png} , jpg={jpg} , bmp={bmp}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = os.path.join(data_dir+'/train.json')\n",
    "val_json = os.path.join(data_dir+'/val.json')\n",
    "\n",
    "with open(train_json , 'r') as file:\n",
    "    train_anno = json.load(file)\n",
    "    \n",
    "train_anno.keys() , train_anno['images'][0] , train_anno['annotations'][0] , train_anno['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SARDet(data_dir= data_dir , imgs = train , mode = 'train')\n",
    "val_set = SARDet(data_dir= data_dir , imgs = val , mode = 'val')\n",
    "test_set = SARDet(data_dir= data_dir , imgs = test , mode = 'test')\n",
    "len(train_set) , len(val_set) , len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_set , batch_size = BATCH_SIZE , shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_set , batch_size = BATCH_SIZE , shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_set , batch_size = BATCH_SIZE , shuffle = False)\n",
    "len(train_loader),len(val_loader),len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = val_set[999]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sample['image_tensor'].numpy()\n",
    "image = np.transpose(image , (1 , 2 , 0))\n",
    "print(\"image size : \" , image.shape)\n",
    "\n",
    "fig , ax = plt.subplots(1)\n",
    "ax.imshow(image , cmap='viridis')\n",
    "\n",
    "for i in range(len(sample['bboxes'])):\n",
    "    box = sample['bboxes'][i]\n",
    "    rect = patches.Rectangle((box[0], box[1]), box[2], box[3], linewidth=3, edgecolor='r', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detector().to(device)\n",
    "summary(model , input_size=(3,256 , 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.random.randint(0, 1, (800, 800, 3))  # Generate a random 800x800 image with 3 channels (RGB)\n",
    "input_tensor = torch.from_numpy(input_array).float()  # Convert to float tensor\n",
    "print(input_tensor.shape)\n",
    "input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0)  \n",
    "\n",
    "input_tensor = input_tensor.to(device)\n",
    "# Pass the input tensor through the model\n",
    "outputs = model(input_tensor)  # Ensure model is in evaluation mode if not training: model.eval()\n",
    "outputs[: , : , 0 , 0] , outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import convert_to_mins_maxes , non_max_suppression , process_boxes\n",
    "from model import decode_outputs\n",
    "\n",
    "boxes , object , class_scores = decode_outputs(outputs) \n",
    "print(f\"After decoding : {boxes.shape} , {object.shape} , {class_scores.shape}\")\n",
    "boxes = boxes.reshape(-1, 4)\n",
    "class_scores = class_scores.reshape(-1, 6)\n",
    "print(boxes.shape)\n",
    "print(class_scores.shape)\n",
    "assert boxes.shape[0] == class_scores.shape[0], \"Mismatch in bounding boxes and class scores counts\"\n",
    "picked_boxes, picked_scores, picked_classes = non_max_suppression(boxes,class_scores)\n",
    "len(picked_boxes) , len(picked_scores) , len(picked_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train\n",
    "\n",
    "train(model = model , train_loader=train_loader , val_loader=val_loader ,\n",
    "      lr = 0.001 , lr_schedule = 'exponential' , epochs = 2 , \n",
    "      out_dir = None , device = device )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN-VS-ViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
