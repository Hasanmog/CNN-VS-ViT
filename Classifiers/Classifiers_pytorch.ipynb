{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from utils import  format_for_display\n",
    "from DataLoader import EuroSAT\n",
    "from engine import train_one_epoch , test_one_epoch\n",
    "from torchvision import  transforms\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "transform = transforms.Compose([\n",
    "    ToTensor() , \n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) ,    \n",
    "])\n",
    "BATCH_SIZE = 8 \n",
    "LR = 0.001\n",
    "Epochs = 25 \n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"datasets/EuroSAT/train.csv\" , index_col = 0)\n",
    "test_csv = pd.read_csv(\"datasets/EuroSAT/test.csv\" , index_col = 0)\n",
    "val_csv = pd.read_csv(\"datasets/EuroSAT/validation.csv\" , index_col = 0)\n",
    "\n",
    "train_csv = train_csv.sort_values(axis = 0 , by = ['ClassName'])\n",
    "test_csv = test_csv.sort_values(axis = 0 , by = ['ClassName'])\n",
    "val_csv = val_csv.sort_values(axis = 0 , by = ['ClassName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/EuroSAT/label_map.json\" , 'r') as file:\n",
    "    labels = json.load(file)\n",
    "    class_names = list(labels.keys())\n",
    "class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "val_set = []\n",
    "sets = [train_csv , val_csv , test_csv]\n",
    "\n",
    "for i , set in enumerate(sets):\n",
    "    if i == 0:\n",
    "        for index, row in set.iterrows():\n",
    "            train_set.append(list(row))\n",
    "    elif i == 2:\n",
    "        for index, row in set.iterrows():\n",
    "            test_set.append(list(row))\n",
    "            \n",
    "    else: \n",
    "        for index, row in set.iterrows():\n",
    "            val_set.append(list(row))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = EuroSAT(parent_dir = \"datasets/EuroSAT\" , data = train_set , transform = transform)\n",
    "val = EuroSAT(parent_dir = \"datasets/EuroSAT\" , data = val_set , transform = transform)\n",
    "test = EuroSAT(parent_dir = \"datasets/EuroSAT\" , data = test_set , transform = transform)\n",
    "\n",
    "len(train) , len(val) , len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train , shuffle = True , batch_size=BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val , shuffle = True , batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle = True , batch_size=BATCH_SIZE)\n",
    "\n",
    "len(train_loader) , len(val_loader)  , len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "first_batch = next(train_iter)\n",
    "images , labels  = first_batch\n",
    "\n",
    "images.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_images = format_for_display(images)\n",
    "    \n",
    "images[0].shape , formatted_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncolumns = 4\n",
    "fig, axs = plt.subplots(nrows, ncolumns, figsize=(15, 6))\n",
    "\n",
    "# Flatten the axs array to simplify accessing individual subplots\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(len(images)):\n",
    "    ax = axs[i]  # Access the individual subplot\n",
    "    ax.imshow(formatted_images[i])  # Display the image\n",
    "    ax.set_title(class_names[labels[i]])  # Set the title to the class name of the image\n",
    "    ax.axis('off')  # Hide the axis\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN using Pytorch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classifiers import NN_1 , NN_2 , NN_3 , NN_4\n",
    "\n",
    "model = NN_4().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = LR)\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "scheduler = \"exponential\"\n",
    "if scheduler == \"onecyclelr\":\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(train_loader), epochs=Epochs, pct_start=0.2)\n",
    "elif scheduler == \"multi_step_lr\":\n",
    "    lr_drop_list = [4, 8]\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_drop_list)\n",
    "elif scheduler == \"step_lr\":\n",
    "    step_size = 10\n",
    "    gamma = 0.5\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = step_size , gamma = gamma)\n",
    "else:\n",
    "    gamma = 0.95\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer , gamma)\n",
    "summary(model , input_size=( 3 , 64 , 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'weights/best_checkpoint.pth'\n",
    "train_loss , val_loss , current_lr = train_one_epoch(model ,\n",
    "                                     training_loader=train_loader ,\n",
    "                                     validation_loader = val_loader ,\n",
    "                                     optimizer=optimizer ,\n",
    "                                     lr_scheduler = lr_scheduler , \n",
    "                                     epochs = Epochs , \n",
    "                                     loss_func = cross_entropy ,\n",
    "                                     device = device ,\n",
    "                                     out_dir = out_dir , \n",
    "                                     resume = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"weights/best_checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "test_loss = test_one_epoch(model = model , test_loader= test_loader , loss_func=cross_entropy , device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)\n",
    "first_batch = next(test_iter)\n",
    "images , labels  = first_batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(images).to('cpu')\n",
    "logits = logits.numpy()\n",
    "pred_classes = np.argmax(logits, axis=1)\n",
    "pred_classes , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_images  = format_for_display(images)\n",
    "nrows = 2\n",
    "ncolumns = 4\n",
    "fig, axs = plt.subplots(nrows, ncolumns, figsize=(15, 6))\n",
    "\n",
    "# Flatten the axs array to simplify accessing individual subplots\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Ensure you have a variable called class_names that maps label indices to actual names\n",
    "# e.g., class_names = {0: 'cat', 1: 'dog', ...}\n",
    "\n",
    "for i in range(len(formatted_images)):\n",
    "    ax = axs[i]  # Access the individual subplot\n",
    "    ax.imshow(formatted_images[i])  # Assuming images[i] is a torch tensor; permute to change the channel order for matplotlib\n",
    "    # Include both GT and predicted class names in the title\n",
    "    title = f'Predicted: {class_names[pred_classes[i]]}\\nGT: {class_names[labels[i].item()]}'\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')  # Hide the axis\n",
    "\n",
    "# Adjust the layout to prevent the titles from overlapping\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
