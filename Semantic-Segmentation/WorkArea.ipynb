{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from dataloader import Drone\n",
    "from utils import dataset_split\n",
    "from torchvision import transforms\n",
    "from model import Segmentor\n",
    "from utils import calculate_iou\n",
    "from engine import train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into train/test/val --> 280/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"../Datasets/Aerial-Semantic-Segmentation-Drone-Dataset\"\n",
    "img_dir = \"../Datasets/Aerial-Semantic-Segmentation-Drone-Dataset/dataset/semantic_drone_dataset/original_images\"\n",
    "masks_dir = \"../Datasets/Aerial-Semantic-Segmentation-Drone-Dataset/RGB_color_image_masks/RGB_color_image_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images , masks = dataset_split(img_dir , masks_dir)\n",
    "train , test , val = images[0] , images[1] , images[2]\n",
    "train_mask , test_mask , val_mask = masks[0] , masks[1] , masks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the effect of downsizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the original image\n",
    "image = Image.open(os.path.join(img_dir, train[0])).convert(\"RGB\")\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((512, 512))  # Use a smaller size to see the downsizing effect\n",
    "])\n",
    "\n",
    "# Apply the transformation\n",
    "image_2 = trans(image)\n",
    "\n",
    "image = np.array(image)\n",
    "image_2 = np.array(image_2)\n",
    "\n",
    "# Plot the original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image (4000 , 6000)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the transformed (resized) image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_2)\n",
    "plt.title(\"Resized Image (512 x 512)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "BATCH_SIZE = 4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.001\n",
    "scheduler = \"exponential\"\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Drone(parent_dir=parent_dir , \n",
    "                      images = train , \n",
    "                      masks = train_mask)\n",
    "\n",
    "val_dataset = Drone(parent_dir=parent_dir , \n",
    "                      images = val , \n",
    "                      masks = val_mask)\n",
    "\n",
    "test_dataset = Drone(parent_dir=parent_dir , \n",
    "                      images = test , \n",
    "                      masks = test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "len(train_loader) , len(test_loader) , len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "batch = next(train_iter)\n",
    "images , masks = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 # sample number from the batch\n",
    "mask = masks[index].squeeze()\n",
    "image = images[index]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.unsqueeze(dim = 0).permute(1 , 2 , 0)\n",
    "mask = mask.numpy()\n",
    "img = image.permute(1 , 2 , 0)\n",
    "img = img.numpy()\n",
    "\n",
    "fig , axs = plt.subplots(nrows = 1 , ncols = 2 , figsize = (10 , 10))\n",
    "axs[0].imshow(img)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(mask)\n",
    "axs[1].set_title(\"Mask\")\n",
    "axs[1].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmentor().to(device)\n",
    "summary(model , input_size=( 3 , 512 , 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss , train_iou , val_loss , val_iou = train_val(model = model , \n",
    "                                                        train_loader = train_loader, \n",
    "                                                        val_loader = val_loader, \n",
    "                                                        epochs = epochs, \n",
    "                                                        lr = lr, \n",
    "                                                        device = device , \n",
    "                                                        lr_schedule=scheduler , \n",
    "                                                        out_dir = \"weights/best_checkpoint.pth\" , \n",
    "                                                        neptune_config=\"../neptune.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
