{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from dataloader import WHU\n",
    "from utils import dataset_split\n",
    "from torchvision import transforms\n",
    "from model import Segmentor\n",
    "from utils import  plot\n",
    "from engine import train_val , test , matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into train/test/val --> 280/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../Datasets/WHU-Bldg/dataset/train\"\n",
    "val_dir = \"../Datasets/WHU-Bldg/dataset/val\"\n",
    "test_dir = \"../Datasets/WHU-Bldg/dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the effect of downsizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "# Open the original image\n",
    "image = Image.open(os.path.join(train_dir,f\"Images/{index}.png\")).convert(\"RGB\")\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((512, 512))  # Use a smaller size to see the downsizing effect\n",
    "])\n",
    "\n",
    "# Apply the transformation\n",
    "image_2 = Image.open(os.path.join(train_dir,f\"Masks/{index}.png\"))\n",
    "\n",
    "image = np.array(image)\n",
    "image_2 = np.array(image_2)\n",
    "\n",
    "\n",
    "fig , axs = plt.subplots(nrows= 1 , ncols=2 , figsize = (10,10))\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[0].set_axis_off()\n",
    "axs[1].imshow(image_2 , cmap = 'viridis')\n",
    "axs[1].set_title(\"Mask\")\n",
    "axs[1].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "BATCH_SIZE = 2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.001\n",
    "scheduler = \"exponential\"\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for massachuesstes dataset\n",
    "\n",
    "train_dataset = WHU(parent_dir=\"../Datasets/Massachusetts/png/Train\")\n",
    "\n",
    "val_dataset = WHU(parent_dir=\"../Datasets/Massachusetts/png/Val\")\n",
    "\n",
    "test_dataset = WHU(parent_dir=\"../Datasets/Massachusetts/png/Test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True , drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False , drop_last=True)\n",
    "len(train_loader) , len(test_loader) , len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WHU(parent_dir=train_dir)\n",
    "\n",
    "val_dataset = WHU(parent_dir=val_dir)\n",
    "\n",
    "test_dataset = WHU(parent_dir=test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True , drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False , drop_last=True)\n",
    "len(train_loader) , len(test_loader) , len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = iter(test_loader)\n",
    "batch = next(val_iter)\n",
    "images , masks = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3 # sample number from the batch\n",
    "mask = masks[index].squeeze()\n",
    "image = images[index]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.unsqueeze(dim = 0).permute(1 , 2 , 0)\n",
    "mask = mask.numpy()\n",
    "img = image.permute(1 , 2 , 0)\n",
    "img = img.numpy()\n",
    "\n",
    "fig , axs = plt.subplots(nrows = 1 , ncols = 2 , figsize = (10 , 10))\n",
    "axs[0].imshow(img)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(mask)\n",
    "axs[1].set_title(\"Mask\")\n",
    "axs[1].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmentor().to(device)\n",
    "summary(model , input_size=( 3 , 512 , 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss , val_loss  = train_val(model = model , \n",
    "                                                        train_loader = train_loader, \n",
    "                                                        val_loader = val_loader, \n",
    "                                                        epochs = epochs, \n",
    "                                                        lr = lr, \n",
    "                                                        device = device , \n",
    "                                                        lr_schedule=scheduler , \n",
    "                                                        out_dir = \"weights/resume\" ,\n",
    "                                                        neptune_config=\"../neptune.json\",\n",
    "                                                        pretrain_checkpoint=\"weights/best_checkpoint.pth\", \n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test(model , test_loader=test_loader , checkpoint = \"weights/resume/best_checkpoint.pth\" , \n",
    "                             device = device,\n",
    "                             output_dir= \"results\" , \n",
    "                             name = \"results_mass\" , \n",
    "                             postprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"length of test dataset:{len(test_loader)} batches\")\n",
    "test_iter = iter(test_loader)\n",
    "batch_numb = 2 #starts from zero\n",
    "for i in range(batch_numb):\n",
    "    batch = next(test_iter)\n",
    "    images , masks = batch\n",
    "#3\n",
    "# batch = next(test_iter)\n",
    "# images , masks = batch\n",
    "\n",
    "#images --> [batch, 3 , 512 , 512]    / masks --> [batch , 1 , 512 , 512]\n",
    "# pred_masks --> outputs --> [batch , 1 , 512 , 512]\n",
    "plot(model = model , images = images , gt_masks = masks , checkpoint=\"weights/best_checkpoint.pth\", device = device , with_postprocess = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
