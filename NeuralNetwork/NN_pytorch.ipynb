{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import neptune\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torchsummary import summary\n",
    "from utils import scale_to_unit_range\n",
    "from DataLoader import EuroSAT\n",
    "from engine import train_one_epoch , test_one_epoch\n",
    "from torchvision import datasets , transforms\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "transform = transforms.Compose([\n",
    "    ToTensor() , \n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) ,    \n",
    "])\n",
    "BATCH_SIZE = 8 \n",
    "LR = 0.001\n",
    "Epochs = 25 \n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"EuroSAT/train.csv\" , index_col = 0)\n",
    "test_csv = pd.read_csv(\"EuroSAT/test.csv\" , index_col = 0)\n",
    "val_csv = pd.read_csv(\"EuroSAT/validation.csv\" , index_col = 0)\n",
    "\n",
    "train_csv = train_csv.sort_values(axis = 0 , by = ['ClassName'])\n",
    "test_csv = test_csv.sort_values(axis = 0 , by = ['ClassName'])\n",
    "val_csv = val_csv.sort_values(axis = 0 , by = ['ClassName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EuroSAT/label_map.json\" , 'r') as file:\n",
    "    labels = json.load(file)\n",
    "    class_names = list(labels.keys())\n",
    "class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "val_set = []\n",
    "sets = [train_csv , val_csv , test_csv]\n",
    "\n",
    "for i , set in enumerate(sets):\n",
    "    if i == 0:\n",
    "        for index, row in set.iterrows():\n",
    "            train_set.append(list(row))\n",
    "    elif i == 2:\n",
    "        for index, row in set.iterrows():\n",
    "            test_set.append(list(row))\n",
    "            \n",
    "    else: \n",
    "        for index, row in set.iterrows():\n",
    "            val_set.append(list(row))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = EuroSAT(parent_dir = \"EuroSAT\" , data = train_set , transform = transform)\n",
    "val = EuroSAT(parent_dir = \"EuroSAT\" , data = val_set , transform = transform)\n",
    "test = EuroSAT(parent_dir = \"EuroSAT\" , data = test_set , transform = transform)\n",
    "\n",
    "len(train) , len(val) , len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train , shuffle = True , batch_size=BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val , shuffle = True , batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle = False , batch_size=BATCH_SIZE)\n",
    "\n",
    "len(train_loader) , len(val_loader)  , len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "first_batch = next(train_iter)\n",
    "images , labels  = first_batch\n",
    "\n",
    "images.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_images  = []\n",
    "for image in images:\n",
    "    image = image.permute(1 , 2 , 0)\n",
    "    image = scale_to_unit_range(image)\n",
    "    image = image.numpy()\n",
    "    formatted_images.append(image)\n",
    "    \n",
    "images[0].shape , formatted_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncolumns = 4\n",
    "fig, axs = plt.subplots(nrows, ncolumns, figsize=(15, 6))\n",
    "\n",
    "# Flatten the axs array to simplify accessing individual subplots\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(len(images)):\n",
    "    ax = axs[i]  # Access the individual subplot\n",
    "    ax.imshow(formatted_images[i])  # Display the image\n",
    "    ax.set_title(class_names[labels[i]])  # Set the title to the class name of the image\n",
    "    ax.axis('off')  # Hide the axis\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN using Pytorch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Class_Model(nn.Module):\n",
    "    def __init__(self , num_classes = 10 , device = device ): # batch --> (BATCH_SIZE , 3 , 64 , 64 )\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels = 3 , out_channels= 16 , kernel_size=3) # (16 , 62 , 62)\n",
    "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
    "        self.act_1 = nn.ReLU()\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels = 16 ,out_channels = 64 , kernel_size = 5) # (64 , 58 , 58)\n",
    "        self.batch_norm_2  = nn.BatchNorm2d(64)\n",
    "        self.act_2 = nn.ReLU()\n",
    "        self.flatten = nn.Flatten() # (64 , 58 ,58)\n",
    "        self.fc1 = nn.Linear(64*58*58 , 16)\n",
    "        self.fc2 = nn.Linear(16 , num_classes)\n",
    "        self.act_3 = nn.LogSoftmax() ## nn.logsoftmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device) \n",
    "        conv2d_1 = self.conv2d_1(x)\n",
    "        batch_norm1 = self.batch_norm_1(conv2d_1)\n",
    "        act_1 = self.act_1(batch_norm1)\n",
    "        conv2d_2 = self.conv2d_2(act_1)\n",
    "        batch_norm_2 = self.batch_norm_2(conv2d_2)\n",
    "        act_2 = self.act_2(batch_norm_2)\n",
    "        flatten = self.flatten(act_2)\n",
    "        fc1 = self.fc1(flatten)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        logits = self.act_3(fc2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Class_Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = LR)\n",
    "summary(model , input_size=( 3 , 64 , 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "run = neptune.init_run(\n",
    "    project='Solo/Solo',  # specify your project name here\n",
    "    api_token= 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzZjFkNjIxNy1jOWZlLTQzZTUtYTA3OS0zMjhlM2UwNTMzODYifQ==',\n",
    "    #with_id = 'VLMEO-1048'\n",
    ")\n",
    "\n",
    "losses = 0\n",
    "out_dir = 'weights/NN_attempt_1/best_checkpoint.pth'\n",
    "for epoch in tqdm(range(Epochs)):\n",
    "    \n",
    "    print(f\"Epoch number : {epoch + 1}\")\n",
    "    \n",
    "    train_loss , val_loss = train_one_epoch(model , training_loader=train_loader ,\n",
    "                                     validation_loader = val_loader ,\n",
    "                                     optimizer=optimizer ,\n",
    "                                     loss_func = cross_entropy ,\n",
    "                                     device = device ) \n",
    "    \n",
    "    if val_loss > losses:\n",
    "            torch.save({\n",
    "                'epoch' : epoch+1 ,\n",
    "                'model_state_dict': model.state_dict(), \n",
    "                'optimizer_state_dict' : optimizer.state_dict() , \n",
    "                'train_loss' : train_loss , \n",
    "                'val_loss' : val_loss\n",
    "            } , out_dir)\n",
    "            \n",
    "            losses = val_loss\n",
    "    run['training loss per Epoch'].log(train_loss)\n",
    "    run['validation loss per Epoch'].log(val_loss)\n",
    "    \n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights/NN_attempt_1/best_checkpoint.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict[checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(Epochs)):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"weights/NN_attempt_1/best_checkpoint.pth\")\n",
    "model.load_state_dict[checkpoint['model_state_dict']]\n",
    "optimizer.load_state_dict[checkpoint['optimizer_state_dict']]\n",
    "\n",
    "for epoch in tqdm(range(Epochs)):\n",
    "    print(f\"Epoch number : {epoch + 1}\")\n",
    "    \n",
    "    test_loss = test_one_epoch(model = model , test_loader= test_loader , loss_func=cross_entropy , device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper2code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
